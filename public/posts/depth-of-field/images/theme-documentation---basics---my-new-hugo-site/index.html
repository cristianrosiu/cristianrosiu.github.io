<!DOCTYPE html>
<html lang="en">
    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
        <meta charset="utf-8">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp" />
        <title> - My New Hugo Site</title><meta name="Description" content="This is my cool site"><meta property="og:url" content="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/">
  <meta property="og:site_name" content="My New Hugo Site">
  <meta property="og:title" content="My New Hugo Site">
  <meta property="og:description" content="&lt;!DOCTYPE html&gt;Theme Documentation - Basics - My New Hugo SiteMy cool sitePosts Tags Categories My cool siteCancelPostsTagsCategoriesContentsAnatomy of Depth of FieldReal-world Cameras and DOFAperture and its Impact on DOFFocal Length and ZoomingFocal Distance (or Focal Plane)Circle of Confusion ExplainedFrom Real Cameras to Computer GraphicsMethods for Rendering DOFSimulating DOF (Ground Truth)Scatter-Based (Forward Mapping) MethodGather-Based (Backward Mapping)Scatter-as-you-Gather (Hybrid Method)ReferencesTheme Documentation - BasicsDillon included in Computer-Graphics 2020-03-06  4162 words  20 minutes ContentsAnatomy of Depth of FieldDepth of Field (DOF) is a popular effect, used to convey a sense of of depth to a large scene, or in some cases, used as an artistic tool to transmit certain emotions and to alter the composition of a scene.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">

  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="My New Hugo Site">
  <meta name="twitter:description" content="&lt;!DOCTYPE html&gt;Theme Documentation - Basics - My New Hugo SiteMy cool sitePosts Tags Categories My cool siteCancelPostsTagsCategoriesContentsAnatomy of Depth of FieldReal-world Cameras and DOFAperture and its Impact on DOFFocal Length and ZoomingFocal Distance (or Focal Plane)Circle of Confusion ExplainedFrom Real Cameras to Computer GraphicsMethods for Rendering DOFSimulating DOF (Ground Truth)Scatter-Based (Forward Mapping) MethodGather-Based (Backward Mapping)Scatter-as-you-Gather (Hybrid Method)ReferencesTheme Documentation - BasicsDillon included in Computer-Graphics 2020-03-06  4162 words  20 minutes ContentsAnatomy of Depth of FieldDepth of Field (DOF) is a popular effect, used to convey a sense of of depth to a large scene, or in some cases, used as an artistic tool to transmit certain emotions and to alter the composition of a scene.">
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" />
        <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png"><link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="/site.webmanifest"><link rel="canonical" href="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/" /><link rel="next" href="http://192.168.0.124:1313/posts/depth-of-field/" /><link rel="stylesheet" href="/css/style.min.css"><link rel="preload" href="/lib/fontawesome-free/all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="preload" href="/lib/animate/animate.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/192.168.0.124:1313\/posts\/depth-of-field\/images\/theme-documentation---basics---my-new-hugo-site\/"
        },"genre": "posts","wordcount":  4268 ,
        "url": "http:\/\/192.168.0.124:1313\/posts\/depth-of-field\/images\/theme-documentation---basics---my-new-hugo-site\/","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "xxxx"
            },"description": ""
    }
    </script></head>
    <body data-header-desktop="fixed" data-header-mobile="auto"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="/" title="My New Hugo Site">My cool site</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="/posts/"> Posts </a><a class="menu-item" href="/tags/"> Tags </a><a class="menu-item" href="/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-desktop">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="/" title="My New Hugo Site">My cool site</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="/posts/" title="">Posts</a><a class="menu-item" href="/tags/" title="">Tags</a><a class="menu-item" href="/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop"></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content" id="toc-content-auto"></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX"></h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>xxxx</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="0001-01-01">0001-01-01</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;4268 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;21 minutes&nbsp;</div>
        </div><div class="details toc" id="toc-static"  data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><!DOCTYPE html>
<!-- saved from url=(0044)http://localhost:52128/posts/depth-of-field/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script src="./Theme Documentation - Basics - My New Hugo Site_files/livereload.js" data-no-instant="" defer=""></script>
        
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="robots" content="noodp">
        <title>Theme Documentation - Basics - My New Hugo Site</title><meta name="Description" content="This is my cool site"><meta property="og:url" content="http://localhost:52128/posts/depth-of-field/">
  <meta property="og:site_name" content="My New Hugo Site">
  <meta property="og:title" content="Theme Documentation - Basics">
  <meta property="og:description" content="Anatomy of Depth of Field Depth of Field (DOF) is a popular effect, used to convey a sense of of depth to a large scene, or in some cases, used as an artistic tool to transmit certain emotions and to alter the composition of a scene.
As the term “depth of field” intuitively suggests, it describes the range of distances from the camera within which objects appear sharp and fully in focus (Figure 1). Areas positioned closer or farther away than this range become progressively blurred. Before diving deeper into the computational methods and graphics implementations, let’s take a moment to explore how DOF occurs naturally in physical cameras .">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2020-03-06T21:29:01+08:00">
    <meta property="article:modified_time" content="2020-03-06T21:29:01+08:00">
    <meta property="article:tag" content="Depth-of-Field">
    <meta property="article:tag" content="Circle-of-Confusion">
    <meta property="article:tag" content="Dof">
    <meta property="article:tag" content="COC">
    <meta property="og:image" content="http://localhost:52128/posts/depth-of-field/images/thumbnail-color.jpg">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="http://localhost:52128/posts/depth-of-field/images/thumbnail-color.jpg">
  <meta name="twitter:title" content="Theme Documentation - Basics">
  <meta name="twitter:description" content="Anatomy of Depth of Field Depth of Field (DOF) is a popular effect, used to convey a sense of of depth to a large scene, or in some cases, used as an artistic tool to transmit certain emotions and to alter the composition of a scene.
As the term “depth of field” intuitively suggests, it describes the range of distances from the camera within which objects appear sharp and fully in focus (Figure 1). Areas positioned closer or farther away than this range become progressively blurred. Before diving deeper into the computational methods and graphics implementations, let’s take a moment to explore how DOF occurs naturally in physical cameras .">
<meta name="application-name" content="My cool site">
<meta name="apple-mobile-web-app-title" content="My cool site"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#da532c"><link rel="shortcut icon" type="image/x-icon" href="http://localhost:52128/favicon.ico">
        <link rel="icon" type="image/png" sizes="32x32" href="http://localhost:52128/favicon-32x32.png">
        <link rel="icon" type="image/png" sizes="16x16" href="http://localhost:52128/favicon-16x16.png"><link rel="apple-touch-icon" sizes="180x180" href="http://localhost:52128/apple-touch-icon.png"><link rel="mask-icon" href="http://localhost:52128/safari-pinned-tab.svg" color="#5bbad5"><link rel="manifest" href="http://localhost:52128/site.webmanifest"><link rel="canonical" href="http://localhost:52128/posts/depth-of-field/"><link rel="stylesheet" href="./Theme Documentation - Basics - My New Hugo Site_files/style.min.css"><link rel="stylesheet" href="./Theme Documentation - Basics - My New Hugo Site_files/all.min.css" as="style" onload="this.onload=null;this.rel=&#39;stylesheet&#39;">
        <noscript><link rel="stylesheet" href="/lib/fontawesome-free/all.min.css"></noscript><link rel="stylesheet" href="./Theme Documentation - Basics - My New Hugo Site_files/animate.min.css" as="style" onload="this.onload=null;this.rel=&#39;stylesheet&#39;">
        <noscript><link rel="stylesheet" href="/lib/animate/animate.min.css"></noscript><script type="application/ld+json">
    {
        "@context": "http://schema.org",
        "@type": "BlogPosting",
        "headline": "Theme Documentation - Basics",
        "inLanguage": "en",
        "mainEntityOfPage": {
            "@type": "WebPage",
            "@id": "http:\/\/localhost:52128\/posts\/depth-of-field\/"
        },"image": [{
                            "@type": "ImageObject",
                            "url": "http:\/\/localhost:52128\/posts\/depth-of-field\/images\/thumbnail-color.jpg",
                            "width":  2560 ,
                            "height":  1369 
                        }],"genre": "posts","keywords": "depth-of-field, circle-of-confusion, dof, COC","wordcount":  4162 ,
        "url": "http:\/\/localhost:52128\/posts\/depth-of-field\/","datePublished": "2020-03-06T21:29:01+08:00","dateModified": "2020-03-06T21:29:01+08:00","publisher": {
            "@type": "Organization",
            "name": ""},"author": {
                "@type": "Person",
                "name": "Dillon"
            },"description": ""
    }
    </script><style id="highlight-mengshou-style">
    .highlight-mengshou-wrap {
        background: #ff9;
        cursor: pointer;
    }
    .highlight-mengshou-wrap.active {
        background: #ffb;
    }
</style></head>
    <body data-header-desktop="fixed" data-header-mobile="auto" theme="dark"><script type="text/javascript">(window.localStorage && localStorage.getItem('theme') ? localStorage.getItem('theme') === 'dark' : ('auto' === 'auto' ? window.matchMedia('(prefers-color-scheme: dark)').matches : 'auto' === 'dark')) && document.body.setAttribute('theme', 'dark');</script>

        <div id="mask"></div><div class="wrapper"><header class="desktop" id="header-desktop">
    <div class="header-wrapper">
        <div class="header-title">
            <a href="http://localhost:52128/" title="My New Hugo Site">My cool site</a>
        </div>
        <div class="menu">
            <div class="menu-inner"><a class="menu-item" href="http://localhost:52128/posts/"> Posts </a><a class="menu-item" href="http://localhost:52128/tags/"> Tags </a><a class="menu-item" href="http://localhost:52128/categories/"> Categories </a><span class="menu-item delimiter"></span><span class="menu-item search" id="search-desktop">
                        <span class="algolia-autocomplete" style="position: relative; display: inline-block; direction: ltr;"><input type="text" placeholder="Search titles or contents..." id="search-input-desktop" class="input" autocomplete="off" spellcheck="false" role="combobox" aria-autocomplete="list" aria-expanded="false" aria-owns="algolia-autocomplete-listbox-0" dir="auto" style="position: relative; vertical-align: top;"><pre aria-hidden="true" style="position: absolute; visibility: hidden; white-space: pre; font-family: system-ui, -apple-system, &quot;Segoe UI&quot;, Roboto, Emoji, Helvetica, Arial, sans-serif; font-size: 16px; font-style: normal; font-variant: normal; font-weight: 400; word-spacing: 0px; letter-spacing: normal; text-indent: 0px; text-rendering: auto; text-transform: none;"></pre></span>
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-desktop" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-desktop" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-desktop">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </span><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                    <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
                </a></div>
        </div>
    </div>
</header><header class="mobile animate__animated animate__faster animate__fadeOutUp" id="header-mobile">
    <div class="header-container">
        <div class="header-wrapper">
            <div class="header-title">
                <a href="http://localhost:52128/" title="My New Hugo Site">My cool site</a>
            </div>
            <div class="menu-toggle" id="menu-toggle-mobile">
                <span></span><span></span><span></span>
            </div>
        </div>
        <div class="menu" id="menu-mobile"><div class="search-wrapper">
                    <div class="search mobile" id="search-mobile">
                        <input type="text" placeholder="Search titles or contents..." id="search-input-mobile">
                        <a href="javascript:void(0);" class="search-button search-toggle" id="search-toggle-mobile" title="Search">
                            <i class="fas fa-search fa-fw" aria-hidden="true"></i>
                        </a>
                        <a href="javascript:void(0);" class="search-button search-clear" id="search-clear-mobile" title="Clear">
                            <i class="fas fa-times-circle fa-fw" aria-hidden="true"></i>
                        </a>
                        <span class="search-button search-loading" id="search-loading-mobile">
                            <i class="fas fa-spinner fa-fw fa-spin" aria-hidden="true"></i>
                        </span>
                    </div>
                    <a href="javascript:void(0);" class="search-cancel" id="search-cancel-mobile">
                        Cancel
                    </a>
                </div><a class="menu-item" href="http://localhost:52128/posts/" title="">Posts</a><a class="menu-item" href="http://localhost:52128/tags/" title="">Tags</a><a class="menu-item" href="http://localhost:52128/categories/" title="">Categories</a><a href="javascript:void(0);" class="menu-item theme-switch" title="Switch Theme">
                <i class="fas fa-adjust fa-fw" aria-hidden="true"></i>
            </a></div>
    </div>
</header><div class="search-dropdown desktop">
        <div id="search-dropdown-desktop" style="position: relative;"><span class="dropdown-menu" role="listbox" id="algolia-autocomplete-listbox-0" style="position: absolute; z-index: 100; display: none; top: 0px; left: 0px; right: auto;"><div class="dataset-search"></div></span></div>
    </div>
    <div class="search-dropdown mobile">
        <div id="search-dropdown-mobile"></div>
    </div><main class="main">
                <div class="container"><div class="toc" id="toc-auto" style="left: 866.68px; max-width: 258.32px; visibility: visible; position: fixed; top: 76px;">
            <h2 class="toc-title">Contents</h2>
            <div class="toc-content always-active" id="toc-content-auto"><nav id="TableOfContents">
  <ul>
    <li><a href="http://localhost:52128/posts/depth-of-field/#anatomy-of-depth-of-field">Anatomy of Depth of Field</a>
      <ul>
        <li><a href="http://localhost:52128/posts/depth-of-field/#real-world-cameras-and-dof">Real-world Cameras and DOF</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#aperture-and-its-impact-on-dof">Aperture and its Impact on DOF</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#focal-length-and-zooming">Focal Length and Zooming</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#focal-distance-or-focal-plane">Focal Distance (or Focal Plane)</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#circle-of-confusion-explained">Circle of Confusion Explained</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#from-real-cameras-to-computer-graphics">From Real Cameras to Computer Graphics</a></li>
      </ul>
    </li>
    <li class="has-active"><a href="http://localhost:52128/posts/depth-of-field/#methods-for-rendering-dof">Methods for Rendering DOF</a>
      <ul>
        <li><a href="http://localhost:52128/posts/depth-of-field/#simulating-dof-ground-truth">Simulating DOF (Ground Truth)</a></li>
        <li class=""><a href="http://localhost:52128/posts/depth-of-field/#scatter-based-forward-mapping-method" class="">Scatter-Based (Forward Mapping) Method</a></li>
        <li class="has-active"><a href="http://localhost:52128/posts/depth-of-field/#gather-based-backward-mapping" class="active">Gather-Based (Backward Mapping)</a></li>
        <li><a href="http://localhost:52128/posts/depth-of-field/#scatter-as-you-gather-hybrid-method">Scatter-as-you-Gather (Hybrid Method)</a></li>
      </ul>
    </li>
    <li><a href="http://localhost:52128/posts/depth-of-field/#references">References</a></li>
  </ul>
</nav></div>
        </div><article class="page single"><h1 class="single-title animate__animated animate__flipInX">Theme Documentation - Basics</h1><div class="post-meta">
            <div class="post-meta-line"><span class="post-author"><a href="http://localhost:52128/" title="Author" rel="author" class="author"><i class="fas fa-user-circle fa-fw" aria-hidden="true"></i>Dillon</a></span>&nbsp;<span class="post-category">included in <a href="http://localhost:52128/categories/computer-graphics/"><i class="far fa-folder fa-fw" aria-hidden="true"></i>Computer-Graphics</a></span></div>
            <div class="post-meta-line"><i class="far fa-calendar-alt fa-fw" aria-hidden="true"></i>&nbsp;<time datetime="2020-03-06">2020-03-06</time>&nbsp;<i class="fas fa-pencil-alt fa-fw" aria-hidden="true"></i>&nbsp;4162 words&nbsp;
                <i class="far fa-clock fa-fw" aria-hidden="true"></i>&nbsp;20 minutes&nbsp;</div>
        </div><div class="featured-image"><img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/thumbnail-color.jpg" data-srcset="/posts/depth-of-field/images/thumbnail-color.jpg, /posts/depth-of-field/images/thumbnail-color.jpg 1.5x, /posts/depth-of-field/images/thumbnail-color.jpg 2x" data-sizes="auto" alt="/posts/depth-of-field/images/thumbnail-color.jpg" title="/posts/depth-of-field/images/thumbnail-color.jpg"></div><div class="details toc" id="toc-static" data-kept="">
                <div class="details-summary toc-title">
                    <span>Contents</span>
                    <span><i class="details-icon fas fa-angle-right" aria-hidden="true"></i></span>
                </div>
                <div class="details-content toc-content" id="toc-content-static"></div>
            </div><div class="content" id="content"><h2 id="anatomy-of-depth-of-field" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#anatomy-of-depth-of-field" class="header-mark"></a>Anatomy of Depth of Field</h2>
<p>Depth of Field (DOF) is a popular effect, used to convey a sense of of depth to a large scene, or in some cases, used as an artistic tool to transmit certain emotions and to alter the composition of a scene.</p>
<p>As the term “depth of field” intuitively suggests, it describes the range of distances from the camera within which objects appear sharp and fully in focus (Figure 1). Areas positioned closer or farther away than this range become progressively blurred. Before diving deeper into the computational methods and graphics implementations, let’s take a moment to explore how DOF occurs naturally in physical cameras .</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/bee-dof-camera.png" title="Bee DOF Camera" data-thumbnail="/posts/depth-of-field/images/bee-dof-camera.png" data-sub-html="&lt;h2&gt;Figure 1: Simplified diagram of what DOF is. In this case, the DOF is the middle green region where the bee and the flower are in-focus.&lt;/h2&gt;&lt;p&gt;Bee DOF Camera&lt;/p&gt;" data-lg-id="06bf95f9-f2b3-4969-9481-9cebd62aae8f">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/bee-dof-camera.png" data-srcset="/posts/depth-of-field/images/bee-dof-camera.png, /posts/depth-of-field/images/bee-dof-camera.png 1.5x, /posts/depth-of-field/images/bee-dof-camera.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/bee-dof-camera.png" width="1480" height="555">
    </a><figcaption class="image-caption">Figure 1: Simplified diagram of what DOF is. In this case, the DOF is the middle green region where the bee and the flower are in-focus.</figcaption>
    </figure><p></p>
<h3 id="real-world-cameras-and-dof" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#real-world-cameras-and-dof" class="header-mark"></a>Real-world Cameras and DOF</h3>
<p>To understand DOF intuitively, we should briefly examine the two key physical components of real cameras: the <strong>image sensor</strong> and the <strong>lens</strong>.</p>
<p>The <strong>image sensor</strong> is essentially a flat, two-dimensional grid composed of millions of tiny, light-sensitive pixels. Each pixel collects incoming photons (particles of light), converting them into digital signals that computers or other digital devices process and store as images [<a href="https://thinklucid.com/tech-briefs/understanding-digital-image-sensors/" target="_blank" rel="noopener noreffer ">1</a>].</p>
<p>The <strong>lens</strong> is equally crucial. Its main role is to bend (or refract) incoming light rays, much like the human eye does. Imagine the lens as a carefully shaped piece of glass designed to redirect parallel incoming rays of light to converge precisely onto a single point on the image sensor. Without a lens, these rays would scatter randomly across the sensor, resulting in blurry and indistinct images. Different types of lenses can converge or diverge rays differently, creating diverse visual effects, but the core principle remains consistent.</p>
<p>In real cameras, the DOF range primarily depends on three key parameters:</p>
<ul>
<li><strong>Aperture</strong>: The diameter and shape of the camera’s opening.</li>
<li><strong>Focal Length</strong>: The distance from the lens to the image sensor (often called the “film-back”).</li>
<li><strong>Focal Distance</strong>: Distance from the center of the lens to the real-life desired subject.</li>
</ul>
<h3 id="aperture-and-its-impact-on-dof" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#aperture-and-its-impact-on-dof" class="header-mark"></a>Aperture and its Impact on DOF</h3>
<p>The <strong>aperture</strong> refers to the size of the camera’s opening through which light enters. In physical terms, the aperture is controlled by an adjustable mechanism known as the <strong>diaphragm</strong>, consisting of multiple overlapping blades arranged in a circular shape. By opening or closing these blades, photographers control how much light enters the camera.</p>
<p>Aperture is measured in <strong>F-stops</strong>, which have an inverse relationship with the diameter of the camera’s opening (Figure 2):</p>
<ul>
<li>Lower F-stop values correspond to larger apertures (wider openings), allowing more light to enter. Larger apertures result in shallower DOF, creating more pronounced blur effects in the foreground and background.</li>
<li>Higher F-stop values correspond to smaller apertures (narrower openings), letting in less light but producing sharper images over a larger range of depths, thus less blur overall.</li>
</ul>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/aperture-animation.gif" title="Aperture Animation" data-thumbnail="/posts/depth-of-field/images/aperture-animation.gif" data-sub-html="&lt;h2&gt;Figure 2: Simplified graphical animation of how the physical size of the aperture is related to f-stops. This shows the inverse relationship between f-stops and size.&lt;/h2&gt;&lt;p&gt;Aperture Animation&lt;/p&gt;" data-lg-id="ff3d0793-8b78-46f8-9fe5-53e3beaf1b37">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/aperture-animation.gif" data-srcset="/posts/depth-of-field/images/aperture-animation.gif, /posts/depth-of-field/images/aperture-animation.gif 1.5x, /posts/depth-of-field/images/aperture-animation.gif 2x" data-sizes="auto" alt="/posts/depth-of-field/images/aperture-animation.gif" width="800" height="500">
    </a><figcaption class="image-caption">Figure 2: Simplified graphical animation of how the physical size of the aperture is related to f-stops. This shows the inverse relationship between f-stops and size.</figcaption>
    </figure><p></p>
<p>Reducing the aperture diameter (increasing F-stop) narrows the cone-shaped paths of the incoming rays. This narrower cone makes it easier for rays originating from different distances to converge closely enough to form a sharper image. At the extreme limit, if the aperture were infinitely small (like a pinhole camera—a theoretical camera model where the aperture is reduced to a tiny pinhole, allowing rays from nearly every distance to converge sharply), you would achieve almost infinite DOF. However, smaller apertures admit less light, potentially causing underexposed (dark) images. Correcting this underexposure through longer exposure times can lead to unwanted motion blur or grainy noise artifacts.</p>
<p>Conversely, wider apertures result in broader cones of incoming rays, increasing divergence and blurring out-of-focus points into a circular shape on the image sensor. This blurred circle has a formal name in photography and rendering: the <strong>Circle of Confusion (CoC)</strong>. All of these concepts will be touched upon in the chapters that will follow.</p>
<h3 id="focal-length-and-zooming" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#focal-length-and-zooming" class="header-mark"></a>Focal Length and Zooming</h3>
<p>The <strong>focal length</strong> describes the distance from the center of the lens to the image sensor (film-back), typically measured in millimeters (usually ranging from 50mm to 100mm). Adjusting the focal length essentially moves the sensor closer to or further away from the lens, changing how “zoomed-in” or “zoomed-out” the resulting image appears. Increasing the focal length (zooming in) narrows your field of view, emphasizing the blur effect in the out-of-focus regions (Figure 3).</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/focal-length-animation.gif" title="Focal Length Animation" data-thumbnail="/posts/depth-of-field/images/focal-length-animation.gif" data-sub-html="&lt;h2&gt;Figure 3: *Visualizing the relationship between lens distances and depth of field. Here, $D$ is the lens-to-object distance, $I$ is the lens-to-filmback distance (also known as focal length), and $F$ represents the lens-to-focal-point distance. Observe that adjusting the lens-to-filmback distance ($I$) effectively scales the projected image—akin to zooming in and out. Importantly, as you zoom in (increase $I$), the blur intensifies due to a narrower depth of field; conversely, zooming out (reducing $I$) sharpens the image, expanding the depth of field.&lt;/h2&gt;&lt;p&gt;Focal Length Animation&lt;/p&gt;" data-lg-id="b8f04d16-f842-495f-bf22-9d1019ddb109">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/focal-length-animation.gif" data-srcset="/posts/depth-of-field/images/focal-length-animation.gif, /posts/depth-of-field/images/focal-length-animation.gif 1.5x, /posts/depth-of-field/images/focal-length-animation.gif 2x" data-sizes="auto" alt="/posts/depth-of-field/images/focal-length-animation.gif" width="800" height="450">
    </a><figcaption class="image-caption">Figure 3: *Visualizing the relationship between lens distances and depth of field. Here, $D$ is the lens-to-object distance, $I$ is the lens-to-filmback distance (also known as focal length), and $F$ represents the lens-to-focal-point distance. Observe that adjusting the lens-to-filmback distance ($I$) effectively scales the projected image—akin to zooming in and out. Importantly, as you zoom in (increase $I$), the blur intensifies due to a narrower depth of field; conversely, zooming out (reducing $I$) sharpens the image, expanding the depth of field.</figcaption>
    </figure><p></p>
<h3 id="focal-distance-or-focal-plane" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#focal-distance-or-focal-plane" class="header-mark"></a>Focal Distance (or Focal Plane)</h3>
<p>The <strong>focal distance</strong> is simply the distance from the center of the camera lens to the subject of the shot. Changing it will alter what objects are considered in-focus and which are out-of-focus. Think of it as moving an imaginary plane on the camera’s forward direction. Any object that is on or close to this imaginary focal plane, will be in-focus. Anything outside the DOF range will be blurred (Figure 4, 5).</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/focal-distance-animation.gif" title="Focal Distance Animation" data-thumbnail="/posts/depth-of-field/images/focal-distance-animation.gif" data-sub-html="&lt;h2&gt;Figure 4: As the object moves away from the static focal plane, its projection on the image sensor grows.&lt;/h2&gt;&lt;p&gt;Focal Distance Animation&lt;/p&gt;" data-lg-id="da18f43c-fd83-425a-a542-83aad100ba01">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/focal-distance-animation.gif" data-srcset="/posts/depth-of-field/images/focal-distance-animation.gif, /posts/depth-of-field/images/focal-distance-animation.gif 1.5x, /posts/depth-of-field/images/focal-distance-animation.gif 2x" data-sizes="auto" alt="/posts/depth-of-field/images/focal-distance-animation.gif" width="800" height="450">
    </a><figcaption class="image-caption">Figure 4: As the object moves away from the static focal plane, its projection on the image sensor grows.</figcaption>
    </figure><p></p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/focal-distance-animation-2.gif" title="Focal Distance Animation 2" data-thumbnail="/posts/depth-of-field/images/focal-distance-animation-2.gif" data-sub-html="&lt;h2&gt;Figure 5: The animation shows how the object remains stationary while the focal plane moves. As the plane shifts away, the object drifts out of focus, becoming increasingly blurred.&lt;/h2&gt;&lt;p&gt;Focal Distance Animation 2&lt;/p&gt;" data-lg-id="8e58c0d1-6947-4521-a6c2-a57bd39687f8">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/focal-distance-animation-2.gif" data-srcset="/posts/depth-of-field/images/focal-distance-animation-2.gif, /posts/depth-of-field/images/focal-distance-animation-2.gif 1.5x, /posts/depth-of-field/images/focal-distance-animation-2.gif 2x" data-sizes="auto" alt="/posts/depth-of-field/images/focal-distance-animation-2.gif" width="800" height="450">
    </a><figcaption class="image-caption">Figure 5: The animation shows how the object remains stationary while the focal plane moves. As the plane shifts away, the object drifts out of focus, becoming increasingly blurred.</figcaption>
    </figure><p></p>
<h3 id="circle-of-confusion-explained" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#circle-of-confusion-explained" class="header-mark"></a>Circle of Confusion Explained</h3>
<p>When out-of-focus objects project onto the sensor, their light rays do not neatly converge to a single point. Instead, these rays spread evenly across an area, creating a uniformly illuminated circular spot known as the <strong>Circle of Confusion</strong> (Figure 6). The shape of this circle depends on the diaphragm blades: more expensive cameras, having more blades, produce smooth, nearly perfect circles; cheaper cameras with fewer blades produce polygons, often pentagonal or hexagonal shapes. This phenomena is known as “bokeh” (Japanese word for blur) and it refers to the distinctive geometric shapes with which are high in local contrast that are mostly visible in the out-of-focus regions of the image (Figure 7).</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/coc-diagram.png" title="CoC Diagram" data-thumbnail="/posts/depth-of-field/images/coc-diagram.png" data-sub-html="&lt;h2&gt;Figure 6: The figure describes how light rays form bokeh through a camera lens. Rays from out-of-focus objects don’t converge to a single point—instead, they spread out, forming shapes on the image plane. These shapes, known as bokeh, are defined by the aperture’s geometry: the number and position of the diaphragm blades. On the left, a lens with more blades produces a smoother, more circular bokeh. On the right, fewer blades result in a more polygonal shape, revealing the mechanical structure behind the blur. Figure courtesy of xeolabs, OpenGL Insights.&lt;/h2&gt;&lt;p&gt;CoC Diagram&lt;/p&gt;" data-lg-id="3bc6d632-e062-43b6-8cdb-6c3f637733e0">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/coc-diagram.png" data-srcset="/posts/depth-of-field/images/coc-diagram.png, /posts/depth-of-field/images/coc-diagram.png 1.5x, /posts/depth-of-field/images/coc-diagram.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/coc-diagram.png" width="1544" height="864">
    </a><figcaption class="image-caption">Figure 6: The figure describes how light rays form bokeh through a camera lens. Rays from out-of-focus objects don’t converge to a single point—instead, they spread out, forming shapes on the image plane. These shapes, known as bokeh, are defined by the aperture’s geometry: the number and position of the diaphragm blades. On the left, a lens with more blades produces a smoother, more circular bokeh. On the right, fewer blades result in a more polygonal shape, revealing the mechanical structure behind the blur. Figure courtesy of xeolabs, OpenGL Insights.</figcaption>
    </figure><p></p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/coc-examples.png" title="CoC Examples" data-thumbnail="/posts/depth-of-field/images/coc-examples.png" data-sub-html="&lt;h2&gt;Figure 7: Rendering of different styles of Bokeh shapes. Figure courtesy of xeolabs, OpenGL Insights.&lt;/h2&gt;&lt;p&gt;CoC Examples&lt;/p&gt;" data-lg-id="7e072b3d-fe31-4910-90cb-912c9add3c84">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/coc-examples.png" data-srcset="/posts/depth-of-field/images/coc-examples.png, /posts/depth-of-field/images/coc-examples.png 1.5x, /posts/depth-of-field/images/coc-examples.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/coc-examples.png" width="1642" height="942">
    </a><figcaption class="image-caption">Figure 7: Rendering of different styles of Bokeh shapes. Figure courtesy of xeolabs, OpenGL Insights.</figcaption>
    </figure><p></p>
<p>In computer graphics, the diameter of the CoC (measured in pixels) provides a practical measure of blur intensity, and hence, the DOF is formally defined as the range within which the CoC remains acceptably small [<a href="https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-28-practical-post-process-depth-field" target="_blank" rel="noopener noreffer ">2</a>]:</p>
<ul>
<li>CoC diameter smaller than one pixel: points appear sharp and in-focus.</li>
<li>CoC diameter greater than one pixel: points blur increasingly as diameter expands.</li>
</ul>
<h3 id="from-real-cameras-to-computer-graphics" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#from-real-cameras-to-computer-graphics" class="header-mark"></a>From Real Cameras to Computer Graphics</h3>
<p>In computer graphics, the virtual cameras we typically use are based on a simplified theoretical ideal camera model—the <strong>pinhole camera</strong>. As mentioned earlier, a pinhole camera has an infinitesimally small aperture (just a point), allowing rays from any distance to converge sharply onto the sensor, resulting in theoretically perfect focus across infinite depth (Figure 8). This model is just a first order approximation of the mapping from 3D to 2D scenes, because it does not take into consideration lense properties such as geometric distortions or blur.</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/pinhole-camera.png" title="Pinhole Camera" data-thumbnail="/posts/depth-of-field/images/pinhole-camera.png" data-sub-html="&lt;h2&gt;Figure 8: Comparison of camera models: Above, a pinhole camera allows rays from an object (here, a tree) to pass through a single infinitesimal aperture, creating a perfectly sharp projection without lens-induced distortion or blur. Below, a real camera incorporates a lens, refracting rays so that they converge at a precise focal point before projecting onto the filmback. This lens-based approach accurately simulates realistic optical effects like DOF, enabling scenes to capture nuanced focal transitions absent from the pinhole model.&lt;/h2&gt;&lt;p&gt;Pinhole Camera&lt;/p&gt;" data-lg-id="edaaf24c-0db7-4e71-bd29-c153f856e97b">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/pinhole-camera.png" data-srcset="/posts/depth-of-field/images/pinhole-camera.png, /posts/depth-of-field/images/pinhole-camera.png 1.5x, /posts/depth-of-field/images/pinhole-camera.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/pinhole-camera.png" width="851" height="681">
    </a><figcaption class="image-caption">Figure 8: Comparison of camera models: Above, a pinhole camera allows rays from an object (here, a tree) to pass through a single infinitesimal aperture, creating a perfectly sharp projection without lens-induced distortion or blur. Below, a real camera incorporates a lens, refracting rays so that they converge at a precise focal point before projecting onto the filmback. This lens-based approach accurately simulates realistic optical effects like DOF, enabling scenes to capture nuanced focal transitions absent from the pinhole model.</figcaption>
    </figure><p></p>
<p>However, since real cameras don’t behave like perfect pinhole cameras, we need computational methods to approximate real-world blur effects. Besides the accumulation buffer method and raytracing, most techniques do this through the approximation of the CoC value. Two common approaches exist:</p>
<ul>
<li><strong>Physically Accurate CoC</strong>: Derived directly from the camera parameters through equations such as the Thin Lens Equation (Figure 9) [<a href="https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques" target="_blank" rel="noopener noreffer ">3</a>].</li>
</ul>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/accurate-coc.png" title="Accurate CoC" data-thumbnail="/posts/depth-of-field/images/accurate-coc.png" data-sub-html="&lt;h2&gt;Figure 9: The diagram shows how the CoC can be calculated using the physical properties of a real camera. The final formula is derived from the thin lense equation.&lt;/h2&gt;&lt;p&gt;Accurate CoC&lt;/p&gt;" data-lg-id="bd1622f6-1bf7-49db-b16c-2134c64dfa6a">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/accurate-coc.png" data-srcset="/posts/depth-of-field/images/accurate-coc.png, /posts/depth-of-field/images/accurate-coc.png 1.5x, /posts/depth-of-field/images/accurate-coc.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/accurate-coc.png" width="450" height="326">
    </a><figcaption class="image-caption">Figure 9: The diagram shows how the CoC can be calculated using the physical properties of a real camera. The final formula is derived from the thin lense equation.</figcaption>
    </figure><p></p>
<ul>
<li><strong>Linear Approximation</strong>: CoC value approximated through a linear function and clamped using Z-buffer values between user-defined bounds (Figure 10) [<a href="http://localhost:52128/posts/depth-of-field/" rel="">4</a>].</li>
</ul>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/approximated-coc.png" title="Approximated CoC" data-thumbnail="/posts/depth-of-field/images/approximated-coc.png" data-sub-html="&lt;h2&gt;Figure 10: Naturally, the size of the CoC (red line) does not change linearly with the distance of objects from the in-focus regions. A simple linear approximation (blue line) can be used to simplify the parameters and reduce the computational overhead. Figure courtesy of xeolabs, OpenGL Insights.&lt;/h2&gt;&lt;p&gt;Approximated CoC&lt;/p&gt;" data-lg-id="bc4adc17-2e5c-4a7f-8bfb-61b56d4f3b3f">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/approximated-coc.png" data-srcset="/posts/depth-of-field/images/approximated-coc.png, /posts/depth-of-field/images/approximated-coc.png 1.5x, /posts/depth-of-field/images/approximated-coc.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/approximated-coc.png" width="1334" height="566">
    </a><figcaption class="image-caption">Figure 10: Naturally, the size of the CoC (red line) does not change linearly with the distance of objects from the in-focus regions. A simple linear approximation (blue line) can be used to simplify the parameters and reduce the computational overhead. Figure courtesy of xeolabs, OpenGL Insights.</figcaption>
    </figure><p></p>
<p>In practice, CoC values are represented in a range (-1, 1), signifying their relative position to the focal plane:</p>
<ul>
<li>Negative values correspond to the Near Field (closer to camera).</li>
<li>Values around zero represent the Focus Field.</li>
<li>Positive values correspond to the Far Field (further from camera).</li>
</ul>
<h2 id="methods-for-rendering-dof" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#methods-for-rendering-dof" class="header-mark"></a>Methods for Rendering DOF</h2>
<p>To efficiently render DOF effects, graphics pipelines generally separate the image into layers based on their CoC:</p>
<ul>
<li><strong>Focus Field</strong>: Near the focal plane (sharp, CoC &lt; 1px).</li>
<li><strong>Near Field</strong>: Closer than the focal plane (blurred foreground).</li>
<li><strong>Far Field</strong>: Farther away than the focal plane (blurred background).</li>
</ul>
<p>Rendering these layers separately simplifies handling different blending behaviors:</p>
<ul>
<li><strong>Near Field</strong>: Requires blending transparency at edges (semi-transparent blur).</li>
<li><strong>Far Field</strong>: Must avoid haloing around sharp objects, handled carefully.</li>
</ul>
<p>Most methods follow this workflow:</p>
<ol>
<li>Calculate per-pixel CoC from depth buffer.</li>
<li>Split image into layers using CoC masks.</li>
<li>Downsample and apply blur to layers independently.</li>
</ol>
<p>In subsequent chapters, we explore various DOF rendering techniques—including Scatter-Based, Gather-Based, and Scatter-As-You-Gather methods—in greater detail.</p>
<h3 id="simulating-dof-ground-truth" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#simulating-dof-ground-truth" class="header-mark"></a>Simulating DOF (Ground Truth)</h3>
<p>To truly understand and evaluate DOF rendering methods in computer graphics, it was important to have a reliable reference—a sort of “ground truth” to compare against. Such a ground truth could be simulated accurately using an approach known as the <strong>Accumulation Buffer (AB)</strong> method. An AB is just a high precision color buffer that is used to store multiple images inside of it [<a href="https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques" target="_blank" rel="noopener noreffer ">3</a>].</p>
<p>Imagine you’re holding a real camera, focusing precisely on an object placed at a certain distance—the focal plane. If you slightly move the camera around this focal plane while always keeping it pointed directly toward it, you’ll notice something interesting:</p>
<ul>
<li>Objects exactly on or near the focal plane stay relatively sharp because their position relative to the sensor doesn’t change significantly.</li>
<li>Objects far away from this plane (either closer or further) shift more dramatically across your sensor from one camera position to another. As you average these multiple views, these areas naturally blur.</li>
</ul>
<p>In the world of computer graphics, the <strong>Accumulation Buffer method</strong> digitally replicates this intuitive physical process. The focal plane stayed fixed, and the virtual camera’s position is moved slightly multiple times, each time capturing a snapshot of the scene from these different viewpoints (Figure 11). These snapshots are then combined—summed up and averaged—to produce the final image.</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/dof-simulation.png" title="DOF Simulation" data-thumbnail="/posts/depth-of-field/images/dof-simulation.png" data-sub-html="&lt;h2&gt;Figure 11: Image shows the simplified process of accurately simulating DOF. In the accumulation buffer technique, the focal plane of the camera is kept stationary while its positions changes, taking a snapshot at each step. Processing all snapshots results in a accurate representation of DOF. Figure courtesy of Akenine-Möller et al., Real-Time Rendering, 4th Edition.&lt;/h2&gt;&lt;p&gt;DOF Simulation&lt;/p&gt;" data-lg-id="de8bb683-9817-43d0-9378-75608f8c0d9f">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/dof-simulation.png" data-srcset="/posts/depth-of-field/images/dof-simulation.png, /posts/depth-of-field/images/dof-simulation.png 1.5x, /posts/depth-of-field/images/dof-simulation.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/dof-simulation.png" width="725" height="635">
    </a><figcaption class="image-caption">Figure 11: Image shows the simplified process of accurately simulating DOF. In the accumulation buffer technique, the focal plane of the camera is kept stationary while its positions changes, taking a snapshot at each step. Processing all snapshots results in a accurate representation of DOF. Figure courtesy of Akenine-Möller et al., Real-Time Rendering, 4th Edition.</figcaption>
    </figure><p></p>
<p>The more snapshots or samples taken, the closer the resulting image is to real-world accuracy. A limited number of snapshot can result in ghosting, just straight up copying of objects, or bending artifacts when high blur is present. As a rule of thumb, you can estimate the number of accumulation passes required for realistic DOF by dividing the area of the largest CoC by the number of pixels you’re willing to tolerate per sample. For high-quality results with minimal banding (limited to about 2×2 pixel blocks), aim for one pass per 4 pixels of CoC area—for example, a CoC with an 8-pixel radius (≈200 pixels in area) would require about 50 passes (200 /4). For a more performance-friendly but lower-quality approximation, you can stretch that to one pass per 9 pixels of CoC area, tolerating up to 3×3 pixel blocks of blur and reducing the pass count significantly—for instance, down to about 12 passes for a 6-pixel-radius CoC. This trade-off between visual fidelity and rendering cost is key when tuning for real-time vs. offline rendering[<a href="https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques" target="_blank" rel="noopener noreffer ">3</a>]. Consequently, there is a significant cost: rendering each viewpoint separately means that this technique is computationally expensive. Because of this, the accumulation buffer method is rarely used directly during real-time rendering. Instead, it serves as a reliable benchmark, allowing developers and artists to qualitatively compare and refine faster but less physically accurate DOF approximations.</p>
<p>All subsequent rendering methods we discuss attempted to approximate this accurate simulation in different ways—each exploring and solving the DOF problem from various perspectives, especially in terms of efficiently approximating the CoC.</p>
<h3 id="scatter-based-forward-mapping-method" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#scatter-based-forward-mapping-method" class="header-mark"></a>Scatter-Based (Forward Mapping) Method</h3>
<p>In scatter-based DOF techniques, each pixel scatters its shading value to its neighbours. Unfortunately, scattering operations do not map well to current shader capabilities as it requires some level of synchronisation that would affect the parallel nature of GPUs. One solution that worked well in practice is the usage of sprites. Each out-of-focus pixel is transformed into a <strong>sprite</strong>—a piece of geometry, typically a rectangle or circle, with a texture attached to it —that represents how much that pixel should blur across the screen. The size of this sprite is driven by the <strong>CoC</strong>, a value derived from the z-buffer.</p>
<p>To build an intuition, imagine a <strong>white square the size of 1 pixel</strong> floating in 2D space. If that pixel is in focus, it stays sharp—affecting only its original screen-space location. We now take that tiny white quad and <strong>scale it up</strong> using the CoC value, spreading it in nearby pixels. The result? Its contribution <strong>overlaps neighboring pixels</strong>.</p>
<p>So rather than computing blur by pulling in nearby samples (as in gather-based methods), <strong>each pixel scatters its own influence outward</strong>, like dropping a pebble and watching ripples expand.</p>
<p>In practice, this is often implemented using a <strong>Geometry Shader</strong>, a programmable stage in the GPU pipeline that can dynamically emit geometry based on input data. Here, it reads the pixel’s depth, calculates its CoC, and then <strong>emits a triangle-based sprite</strong>, scaled accordingly (see Figure 12) [<a href="https://bartwronski.com/2014/04/07/bokeh-depth-of-field-going-insane-part-1/" target="_blank" rel="noopener noreffer ">5</a>]</p>
<p>Geometry information of the sprite is then sent to a Pixel Shader (PS), where a custom bokeh texture is sampled, and each sprite rasterised and blended into the final image using <strong>additive alpha blending</strong>. Additive blending combines the colors of overlapping sprites, creating a cumulative blur effect. Finally, these sprites are composited into a single coherent image by averaging, normalizing, and upscaling the resulting blurred layers.</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/scatter-dof.png" title="Scatter DOF" data-thumbnail="/posts/depth-of-field/images/scatter-dof.png" data-sub-html="&lt;h2&gt;Figure 12: Stages of the scatter-based method using sprites. The CoC is calculated from the z-buffer values then sent to the geometry shader for the creation of triangle or quad based geometry. Finally, all pixels of each sprite sample a custom aperture texture and result is accumulated and composited in the scene using alpha blending. Figure courtesy of Tiago Sousa, Graphics Gems from CryENGINE 3&lt;/h2&gt;&lt;p&gt;Scatter DOF&lt;/p&gt;" data-lg-id="96439848-91fc-4ed4-892f-6e4f90c445da">
        <img class="lazyautosizes ls-is-cached lazyloaded" src="./Theme Documentation - Basics - My New Hugo Site_files/scatter-dof.png" data-src="/posts/depth-of-field/images/scatter-dof.png" data-srcset="/posts/depth-of-field/images/scatter-dof.png, /posts/depth-of-field/images/scatter-dof.png 1.5x, /posts/depth-of-field/images/scatter-dof.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/scatter-dof.png" width="1294" height="1266" sizes="552px" srcset="/posts/depth-of-field/images/scatter-dof.png, /posts/depth-of-field/images/scatter-dof.png 1.5x, /posts/depth-of-field/images/scatter-dof.png 2x">
    </a><figcaption class="image-caption">Figure 12: Stages of the scatter-based method using sprites. The CoC is calculated from the z-buffer values then sent to the geometry shader for the creation of triangle or quad based geometry. Finally, all pixels of each sprite sample a custom aperture texture and result is accumulated and composited in the scene using alpha blending. Figure courtesy of Tiago Sousa, Graphics Gems from CryENGINE 3</figcaption>
    </figure><p></p>
<p>This process is intuitive and straightforward: it is called “scattering” because each blurred pixel scatters its influence outward onto surrounding pixels. However, the scatter-based method faces significant challenges when executed on GPUs:</p>
<ul>
<li>
<p>Graphics Processing Units (GPUs) are designed around massive parallelisation—running thousands of threads simultaneously to render images rapidly. This parallelism relied on threads operating independently with minimal synchronisation. Scattering is equivalent to a write operation, however, doing so on GPUs require multiple threads to coordinate frequently, as they have to write results to overlapping pixel locations simultaneously, causing synchronisation bottlenecks [<a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-32-taking-plunge-gpu" target="_blank" rel="noopener noreffer ">6</a>]. This is partially solved through the usage of sprites, however, the variability in performance yielded by such methods makes them less suitable for real-time applications [<a href="http://localhost:52128/posts/depth-of-field/" rel="">7</a>]. This variability is mostly given by the high fill rate and bandwidth required by drawing a quad for each pixel [<a href="http://localhost:52128/posts/depth-of-field/" rel="">8</a>].</p>
</li>
<li>
<p>Scatter-based methods are notoriously tricky when combined with other translucent effects such as smoke, fog, or particle systems. Since each of these effects also involved transparency and blending, compositing them with scatter-based DOF methods became complicated. Often, developers had to give artists explicit control over the order in which different effects or materials were composited [<a href="https://www.gdcvault.com/play/1014666/-SPONSORED-The-Technology-Behind" target="_blank" rel="noopener noreffer ">9</a>] (e.g., DOF before or after particles), adding complexity and additional time to the artistic workflow (Figure 13)</p>
</li>
</ul>
<p>![Scatter DOF Issue](images/scatter-dof-issue.png “Figure 13: The figure shows special shader graph nodes created to help artist better compiste the DOF post-process effect with other transparent effects. Figure courtesy of Martin Mittring et. al, The Technology Behind the DirectX 11 Unreal Engine “Samaritan” Demo”.)</p>
<h3 id="gather-based-backward-mapping" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#gather-based-backward-mapping" class="header-mark"></a>Gather-Based (Backward Mapping)</h3>
<p>To better understand the gather-based method, let’s first revisit briefly what we learned about scatter-based (forward mapping) methods. Recall that in scatter-based methods, each pixel “spreads” its blur to nearby pixels. While straightforward conceptually, this isn’t very GPU-friendly due to synchronization complexities.</p>
<p><strong>Gather-based methods</strong>, on the other hand, flip this logic upside down. Instead of scattering, each pixel “gathers” or collects information from neighboring pixels around it (Figure 14). Imagine you’re trying to figure out the exact shade of color your pixel should be. Instead of telling your neighbors, “Here’s my blur!”, you ask your neighbors, “What blur should I be seeing here?” This subtle yet important inversion aligns very naturally with GPU architectures because GPUs excel at sampling data from nearby memory locations. Sampling nearby pixels—essentially reading memory that’s close together [<a href="https://www.nocentino.com/Nocentino10.pdf" target="_blank" rel="noopener noreffer ">10</a>]—is exactly the kind of task GPUs do exceptionally efficiently . This hardware capability makes gather-based approaches attractive from both a performance and implementation standpoint</p>
<div class="details admonition tip open">
        <div class="details-summary admonition-title">
            <i class="icon fas fa-lightbulb fa-fw" aria-hidden="true"></i>Tip<i class="details-icon fas fa-angle-right fa-fw" aria-hidden="true"></i>
        </div>
        <div class="details-content">
            <div class="admonition-content"><p>Most of GPUs and Graphic APIs offer the option of hardware-based gather operations on GPU resources (e.g. textures).</p>
<div class="highlight"><div class="chroma open"><div class="code-header language-hlsl"><span class="code-title"><i class="arrow fas fa-chevron-right fa-fw" aria-hidden="true"></i></span><span class="ellipses"><i class="fas fa-ellipsis-h fa-fw" aria-hidden="true"></i></span><span class="copy" data-clipboard-text="float4 samples = myTexture.GatherRed( mySampler, uv + float2(0.5f, 0.5f)/myTextureDim );
float r1 = samples.w;
float r2 = samples.z;
float r3 = samples.x;
float r4 = samples.y;
" title="Copy to clipboard"><i class="far fa-copy fa-fw" aria-hidden="true"></i></span></div><div class="table-wrapper"><table><tbody><tr><td><pre tabindex="0" class="chroma"><code class="language-hlsl" data-lang="hlsl"><span class="line"><span class="cl"><span class="kt">float4</span> <span class="n">samples</span> <span class="o">=</span> <span class="n">myTexture</span><span class="p">.</span><span class="n">GatherRed</span><span class="p">(</span> <span class="n">mySampler</span><span class="p">,</span> <span class="n">uv</span> <span class="o">+</span> <span class="kt">float2</span><span class="p">(</span><span class="mf">0.5f</span><span class="p">,</span> <span class="mf">0.5f</span><span class="p">)</span><span class="o">/</span><span class="n">myTextureDim</span> <span class="p">);</span>
</span></span><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">r1</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="n">w</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">r2</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="n">z</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">r3</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="n">x</span><span class="p">;</span>
</span></span><span class="line"><span class="cl"><span class="kt">float</span> <span class="n">r4</span> <span class="o">=</span> <span class="n">samples</span><span class="p">.</span><span class="n">y</span><span class="p">;</span>
</span></span></code></pre></td></tr></tbody></table></div></div></div></div>
        </div>
    </div>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/scatter-and-gather-op.png" title="Scatter And Gather Operation" data-thumbnail="/posts/depth-of-field/images/scatter-and-gather-op.png" data-sub-html="&lt;h2&gt;Figure 14: Difference between the scatter-based (left) and gather-based (right) methods. Figure courtesy of Akenine-Möller et al., Real-Time Rendering, 4th Edition.&lt;/h2&gt;&lt;p&gt;Scatter And Gather Operation&lt;/p&gt;" data-lg-id="baa71948-9a7b-4226-af9d-2eac79aad0dd">
        <img class="lazyautosizes lazyloaded" src="./Theme Documentation - Basics - My New Hugo Site_files/scatter-and-gather-op.png" data-src="/posts/depth-of-field/images/scatter-and-gather-op.png" data-srcset="/posts/depth-of-field/images/scatter-and-gather-op.png, /posts/depth-of-field/images/scatter-and-gather-op.png 1.5x, /posts/depth-of-field/images/scatter-and-gather-op.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/scatter-and-gather-op.png" width="853" height="378" sizes="552px" srcset="/posts/depth-of-field/images/scatter-and-gather-op.png, /posts/depth-of-field/images/scatter-and-gather-op.png 1.5x, /posts/depth-of-field/images/scatter-and-gather-op.png 2x">
    </a><figcaption class="image-caption">Figure 14: Difference between the scatter-based (left) and gather-based (right) methods. Figure courtesy of Akenine-Möller et al., Real-Time Rendering, 4th Edition.</figcaption>
    </figure><p></p>
<p>The unfortunate aspect about these methods is the <strong>Neighborhood Assumption</strong>. Gathering inherently assumes that neighboring pixels have similar depth values, meaning they’re part of the same object or closely related objects. However, at object boundaries—where depth values shift drastically—this assumption can break down, leading to visible artifacts like haloing.</p>
<p>Let’s visualize this haloing effect intuitively: imagine you’re sampling colors for a pixel at the edge of a in-focus foreground object. Some gathered samples accidentally include background pixels due to a large CoC radius. Blending these distant pixels creates unwanted halos around the object’s edge, breaking visual realism (Figure 15).</p>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/dof-problem-1.png" title="DOF Problem 1" data-thumbnail="/posts/depth-of-field/images/dof-problem-1.png" data-sub-html="&lt;h2&gt;Figure 15: Visualizing common artifacts in gather-based DOF rendering. On the left, the character&#39;s nose is sharply focused against a blurred background. When sampling blurred background pixels near this sharp edge, the gather-based method unintentionally mixes in focused foreground data (due to high CoC radius), causing a noticeable halo around the nose. On the right, the reverse scenario occurs—the character is blurred while the background remains sharp. Here, sharp background details (like the sky) bleed onto the blurred edges of the character. Both cases highlight the fundamental challenge with gather-based methods: they indiscriminately blend pixel information across depth boundaries, resulting in visual artifacts known as haloing and color bleeding. Figure courtesy of Tiago Sousa, Graphics Gems from CryENGINE 3&lt;/h2&gt;&lt;p&gt;DOF Problem 1&lt;/p&gt;" data-lg-id="15cced14-1f53-4309-af27-8852eedf6e0a">
        <img class="lazyautosizes ls-is-cached lazyloaded" src="./Theme Documentation - Basics - My New Hugo Site_files/dof-problem-1.png" data-src="/posts/depth-of-field/images/dof-problem-1.png" data-srcset="/posts/depth-of-field/images/dof-problem-1.png, /posts/depth-of-field/images/dof-problem-1.png 1.5x, /posts/depth-of-field/images/dof-problem-1.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/dof-problem-1.png" width="1014" height="522" sizes="552px" srcset="/posts/depth-of-field/images/dof-problem-1.png, /posts/depth-of-field/images/dof-problem-1.png 1.5x, /posts/depth-of-field/images/dof-problem-1.png 2x">
    </a><figcaption class="image-caption">Figure 15: Visualizing common artifacts in gather-based DOF rendering. On the left, the character's nose is sharply focused against a blurred background. When sampling blurred background pixels near this sharp edge, the gather-based method unintentionally mixes in focused foreground data (due to high CoC radius), causing a noticeable halo around the nose. On the right, the reverse scenario occurs—the character is blurred while the background remains sharp. Here, sharp background details (like the sky) bleed onto the blurred edges of the character. Both cases highlight the fundamental challenge with gather-based methods: they indiscriminately blend pixel information across depth boundaries, resulting in visual artifacts known as haloing and color bleeding. Figure courtesy of Tiago Sousa, Graphics Gems from CryENGINE 3</figcaption>
    </figure><p></p>
<p>Gather-based (backward mapping) methods elegantly leverage GPU strengths by shifting complexity away from scattering information to intelligently gathering it. While highly efficient and broadly effective, handling edge cases at object boundaries remains a nuanced challenge, necessitating careful management of sampling strategies and edge-aware filtering techniques.</p>
<h3 id="scatter-as-you-gather-hybrid-method" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#scatter-as-you-gather-hybrid-method" class="header-mark"></a>Scatter-as-you-Gather (Hybrid Method)</h3>
<p>We’ve previously discussed two distinct approaches for rendering DOF: the <strong>Scatter-Based</strong> method, where each pixel actively spreads its color to neighboring pixels, and the <strong>Gather-Based</strong> method, where each pixel passively pulls colors from its neighbors. Each approach comes with its unique advantages and inherent limitations. Interestingly, there’s a clever hybrid approach—often called the <strong>Scatter-as-you-Gather</strong> method—that blends the strengths of both these worlds.</p>
<p>To combine the efficiency of gathering with the precision of scattering, we use a hybrid method: <strong>scatter-as-you-gather</strong>. This method smartly flips the scattering problem on its head. Instead of each pixel blindly pushing its color outward, pixels carefully examine their neighbors and selectively decide whether a neighbor’s color should “scatter” into them [<a href="http://localhost:52128/posts/depth-of-field/" rel="">11</a>].</p>
<p>Here’s an intuitive breakdown of the process (see <strong>Figure 16</strong> for a visual overview):</p>
<ol>
<li><strong>Gather Phase</strong>: For each pixel, we first gather color and depth information from neighboring pixels within a radius defined by the current pixel’s own CoC. Remember, the CoC size indicates how blurry a pixel should appear—the larger the CoC, the more blurred the pixel.</li>
<li><strong>Scatter Decision (Depth-Based Selection)</strong>: After collecting these neighboring pixels, the algorithm evaluates each neighbor’s own CoC to determine if and how their blurred color could affect the current pixel. Think of this as each pixel “asking” its neighbors: <strong>“Does your blur overlap with my location?”</strong>. To resolve conflicts—where multiple neighboring pixels potentially scatter into one pixel—the algorithm prioritizes by depth: the pixel closest to the camera (lowest z-depth) is chosen as the <strong>near image</strong>. Remaining neighbors close in depth to the neighbor with lowest z-depth are combined using alpha-blending, averaged together and stored in a <strong>foreground</strong> texture. Blending pixels in this manner gets rid of the need for sorting based on depth (which is a common performance bottleneck)</li>
<li><strong>Background Layering and Final Composition</strong>: Pixels that do not significantly scatter into our current pixel (usually those further back or less blurry) are grouped into a separate background layer. Finally, the carefully crafted foreground layer is composited over this background layer using alpha blending to produce the final, visually coherent result.</li>
</ol>
<p></p><figure><a class="lightgallery" href="./Theme Documentation - Basics - My New Hugo Site_files/scatter-as-gather-process.png" title="Scatter As Gather Process" data-thumbnail="/posts/depth-of-field/images/scatter-as-gather-process.png" data-sub-html="&lt;h2&gt;Figure 16: Illustration of the scatter-as-gather approach for DOF rendering. At the center (yellow square) is the current pixel being processed. Surrounding blue dots represent potential sampling positions, defined by the pixel&#39;s CoC radius. Contributions are accumulated from neighboring pixels (white dots) whose blur areas (colored circles) overlap this central pixel. Importantly, these contributions are gathered in depth order—from closest (red) to furthest (magenta)—ensuring proper occlusion and accurate blending of blurred elements. Figure courtesy of Jorge Jimenez, Next Generation Post Processing in Call of Duty: Advanced Warfare&lt;/h2&gt;&lt;p&gt;Scatter As Gather Process&lt;/p&gt;" data-lg-id="10abb93a-f5e2-4ce0-a267-f0996b11ff6a">
        <img class="lazyload" src="./Theme Documentation - Basics - My New Hugo Site_files/loading.min.svg" data-src="/posts/depth-of-field/images/scatter-as-gather-process.png" data-srcset="/posts/depth-of-field/images/scatter-as-gather-process.png, /posts/depth-of-field/images/scatter-as-gather-process.png 1.5x, /posts/depth-of-field/images/scatter-as-gather-process.png 2x" data-sizes="auto" alt="/posts/depth-of-field/images/scatter-as-gather-process.png" width="1626" height="992">
    </a><figcaption class="image-caption">Figure 16: Illustration of the scatter-as-gather approach for DOF rendering. At the center (yellow square) is the current pixel being processed. Surrounding blue dots represent potential sampling positions, defined by the pixel's CoC radius. Contributions are accumulated from neighboring pixels (white dots) whose blur areas (colored circles) overlap this central pixel. Importantly, these contributions are gathered in depth order—from closest (red) to furthest (magenta)—ensuring proper occlusion and accurate blending of blurred elements. Figure courtesy of Jorge Jimenez, Next Generation Post Processing in Call of Duty: Advanced Warfare</figcaption>
    </figure><p></p>
<p>In summary, what sets this method apart comes down to a few key strengths:</p>
<ul>
<li><strong>Reduced Haloing and Edge Artifacts</strong>: By carefully selecting neighboring pixels based on their CoC and depth, this method reduces problematic halos around objects. It’s particularly effective in rendering realistic transitions between blurry foreground objects and the sharp focus region behind them.</li>
<li><strong>Efficient GPU Implementation</strong>: Although the method introduces an extra complexity step—evaluating neighbors—it remains highly compatible with GPU architectures. GPUs excel at independent gather operations, and this hybrid approach leverages that strength while mimicking scattering through a carefully controlled selection process.</li>
<li><strong>No Need for Depth Sorting</strong>: Traditional scatter-based methods might require sorting pixels to correctly composite translucent layers—a computationally expensive process. The hybrid method sidesteps this requirement entirely through smart alpha blending, achieving visually accurate results without performance hits.</li>
</ul>
<p>Despite its strengths, this method isn’t without trade-offs. The shader logic can become quite intricate, especially when handling edge cases involving large blur radii or dense depth discontinuities. More blur means more neighbors to evaluate, which can add up computationally. In practice, optimizations or approximations are often needed to maintain performance in high-CoC scenarios.</p>
<h2 id="references" class="headerLink"><a href="http://localhost:52128/posts/depth-of-field/#references" class="header-mark"></a>References</h2>
<ul>
<li>[1] <a href="https://thinklucid.com/tech-briefs/understanding-digital-image-sensors/" target="_blank" rel="noopener noreffer ">LUCID Vision Labs - Understanding The Digital Image Sensor</a></li>
<li>[2] <a href="https://developer.nvidia.com/gpugems/gpugems3/part-iv-image-effects/chapter-28-practical-post-process-depth-field" target="_blank" rel="noopener noreffer ">GPU Gems 3 - Chapter 28. Practical Post-Process Depth of Field</a></li>
<li>[3] <a href="https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques" target="_blank" rel="noopener noreffer ">GPU Gems 1 - Chapter 23. Depth of Field: A Survey of Techniques</a></li>
<li>[4] GPU Zen: Advanced Rendering Techniques, by Wolfgang Engel</li>
<li>[5] <a href="https://bartwronski.com/2014/04/07/bokeh-depth-of-field-going-insane-part-1/" target="_blank" rel="noopener noreffer ">Bokeh depth of field – going insane! part 1, by Bart Wronski</a></li>
<li>[6] <a href="https://developer.nvidia.com/gpugems/gpugems2/part-iv-general-purpose-computation-gpus-primer/chapter-32-taking-plunge-gpu" target="_blank" rel="noopener noreffer ">GPU Gems 2 - Chapter 32. General Purpose Computing GPUS Primer</a></li>
<li>[7] Real-Time Rendering, 4th Edition, by Tomas Akenine-Möller</li>
<li>[8] <a href="https://xeolabs.com/pdfs/OpenGLInsights.pdf" target="_blank" rel="noopener noreffer ">OpenGL Insights - xeolabs</a></li>
<li>[9] <a href="https://www.gdcvault.com/play/1014666/-SPONSORED-The-Technology-Behind" target="_blank" rel="noopener noreffer ">The Technology Behind the DirectX 11 Unreal Engine “Samaritan” Demo, by Martin Mittring et. al</a></li>
<li>[10] Nocentino, Anthony E., and Philip J. Rhodes. “Optimizing memory access on GPUs using morton order indexing.” Proceedings of the 48th annual ACM Southeast Conference. 2010.</li>
<li>[11] <a href="https://www.iryoku.com/next-generation-post-processing-in-call-of-duty-advanced-warfare/" target="_blank" rel="noopener noreffer ">Next Generation Post Processing in Call of Duty: Advanced Warfare, by Jorge Jimenez</a></li>
</ul>
<hr>
<ul>
<li>
<p>[] <a href="https://ia800704.us.archive.org/32/items/crytek_presentations/Sousa_Graphics_Gems_CryENGINE3.pdf" target="_blank" rel="noopener noreffer ">Graphics Gems from CryENGINE 3, by Tiago Sousa</a></p>
</li>
<li>
<p>[Pharr and Humphreys 10] Matt Pharr and Greg Humphreys. Physically Based Rendering,
Second Edition: From Theory To Implementation, Second edition. San Francisco, CA:
Morgan Kaufmann Publishers Inc., 2010. (PINHOLE CAMERA REF)</p>
</li>
</ul>
</div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 2020-03-06</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://localhost:52128/posts/depth-of-field/" data-title="Theme Documentation - Basics" data-hashtags="depth-of-field,circle-of-confusion,dof,COC"><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://localhost:52128/posts/depth-of-field/" data-hashtag="depth-of-field"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="http://localhost:52128/posts/depth-of-field/" data-title="Theme Documentation - Basics"><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://localhost:52128/posts/depth-of-field/" data-title="Theme Documentation - Basics"><svg role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" data-svg-src="/lib/simple-icons/icons/line.min.svg" class="icon"><path d="M19.365 9.863c.349.0.63.285.63.631.0.345-.281.63-.63.63H17.61v1.125h1.755c.349.0.63.283.63.63.0.344-.281.629-.63.629h-2.386c-.345.0-.627-.285-.627-.629V8.108c0-.345.282-.63.63-.63h2.386c.346.0.627.285.627.63.0.349-.281.63-.63.63H17.61v1.125h1.755zm-3.855 3.016c0 .27-.174.51-.432.596-.064.021-.133.031-.199.031-.211.0-.391-.09-.51-.25l-2.443-3.317v2.94c0 .344-.279.629-.631.629-.346.0-.626-.285-.626-.629V8.108c0-.27.173-.51.43-.595.06-.023.136-.033.194-.033.195.0.375.104.495.254l2.462 3.33V8.108c0-.345.282-.63.63-.63.345.0.63.285.63.63v4.771zm-5.741.0c0 .344-.282.629-.631.629-.345.0-.627-.285-.627-.629V8.108c0-.345.282-.63.63-.63.346.0.628.285.628.63v4.771zm-2.466.629H4.917c-.345.0-.63-.285-.63-.629V8.108c0-.345.285-.63.63-.63.348.0.63.285.63.63v4.141h1.756c.348.0.629.283.629.63.0.344-.282.629-.629.629M24 10.314C24 4.943 18.615.572 12 .572S0 4.943.0 10.314c0 4.811 4.27 8.842 10.035 9.608.391.082.923.258 1.058.59.12.301.079.766.038 1.08l-.164 1.02c-.045.301-.24 1.186 1.049.645 1.291-.539 6.916-4.078 9.436-6.975C23.176 14.393 24 12.458 24 10.314"></path></svg></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://localhost:52128/posts/depth-of-field/" data-title="Theme Documentation - Basics"><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"><i class="fas fa-tags fa-fw" aria-hidden="true"></i>&nbsp;<a href="http://localhost:52128/tags/depth-of-field/">Depth-of-Field</a>,&nbsp;<a href="http://localhost:52128/tags/circle-of-confusion/">Circle-of-Confusion</a>,&nbsp;<a href="http://localhost:52128/tags/dof/">Dof</a>,&nbsp;<a href="http://localhost:52128/tags/coc/">COC</a></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="http://localhost:52128/">Home</a></span>
        </section>
    </div>

    <div class="post-nav"></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.147.7">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.3.0"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope="" itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="http://localhost:52128/" target="_blank">xxxx</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons" class="animate__animated animate__fadeIn animate__faster" style="display: block;"><a href="http://localhost:52128/posts/depth-of-field/#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="http://localhost:52128/posts/depth-of-field/#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><link rel="stylesheet" href="./Theme Documentation - Basics - My New Hugo Site_files/lightgallery-bundle.min.css"><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/autocomplete.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/lunr.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/lazysizes.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/lightgallery.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/lg-thumbnail.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/lg-zoom.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/clipboard.min.js"></script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"lightgallery":true,"search":{"highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30}};</script><script type="text/javascript" src="./Theme Documentation - Basics - My New Hugo Site_files/theme.min.js"></script>

<script type="text/javascript" src="chrome-extension://dlkffcaaoccbofklocbjcmppahjjboce/inject/index.js"></script>
        <div class="lg-container  " id="lg-container-1" tabindex="-1" aria-modal="true" role="dialog">
            <div id="lg-backdrop-1" class="lg-backdrop" style="transition-duration: 300ms;"></div>

            <div id="lg-outer-1" class="lg-outer lg-use-css3 lg-css3 lg-media-overlap lg-slide lg-grab lg-animate-thumb lg-has-thumb lg-can-toggle lg-use-transition-for-zoom lg-hide-items">

              <div id="lg-content-1" class="lg-content">
                <div id="lg-inner-1" class="lg-inner" style="transition-timing-function: ease; transition-duration: 400ms;">
                </div>
                <button type="button" id="lg-prev-1" aria-label="Previous slide" class="lg-prev lg-icon">  </button>
                <button type="button" id="lg-next-1" aria-label="Next slide" class="lg-next lg-icon">  </button>
              </div>
                <div id="lg-toolbar-1" class="lg-toolbar lg-group">
                    
                    <button type="button" aria-label="Close gallery" id="lg-close-1" class="lg-close lg-icon"></button>
                    <a id="lg-download-1" target="_blank" rel="noopener" aria-label="Download" download="" class="lg-download lg-icon"></a><div class="lg-counter" role="status" aria-live="polite">
                <span id="lg-counter-current-1" class="lg-counter-current">1 </span> /
                <span id="lg-counter-all-1" class="lg-counter-all">15 </span></div><button type="button" aria-label="Toggle thumbnails" class="lg-toggle-thumb lg-icon"></button><button id="lg-zoom-in-1" type="button" aria-label="Zoom in" class="lg-zoom-in lg-icon"></button><button id="lg-zoom-out-1" type="button" aria-label="Zoom in" class="lg-zoom-out lg-icon"></button></div>
                    
                <div id="lg-components-1" class="lg-components">
                    <div class="lg-sub-html" role="status" aria-live="polite"></div>
                <div class="lg-thumb-outer lg-thumb-align-middle lg-grab">
        <div class="lg-thumb lg-group" style="transition-duration: 400ms; width: 1275px; position: relative;"><div data-lg-item-id="0" class="lg-thumb-item  active" style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="0" src="./Theme Documentation - Basics - My New Hugo Site_files/bee-dof-camera.png">
        </div><div data-lg-item-id="1" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="1" src="./Theme Documentation - Basics - My New Hugo Site_files/aperture-animation.gif">
        </div><div data-lg-item-id="2" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="2" src="./Theme Documentation - Basics - My New Hugo Site_files/focal-length-animation.gif">
        </div><div data-lg-item-id="3" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="3" src="./Theme Documentation - Basics - My New Hugo Site_files/focal-distance-animation.gif">
        </div><div data-lg-item-id="4" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="4" src="./Theme Documentation - Basics - My New Hugo Site_files/focal-distance-animation-2.gif">
        </div><div data-lg-item-id="5" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="5" src="./Theme Documentation - Basics - My New Hugo Site_files/coc-diagram.png">
        </div><div data-lg-item-id="6" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="6" src="./Theme Documentation - Basics - My New Hugo Site_files/coc-examples.png">
        </div><div data-lg-item-id="7" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="7" src="./Theme Documentation - Basics - My New Hugo Site_files/pinhole-camera.png">
        </div><div data-lg-item-id="8" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="8" src="./Theme Documentation - Basics - My New Hugo Site_files/accurate-coc.png">
        </div><div data-lg-item-id="9" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="9" src="./Theme Documentation - Basics - My New Hugo Site_files/approximated-coc.png">
        </div><div data-lg-item-id="10" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="10" src="./Theme Documentation - Basics - My New Hugo Site_files/dof-simulation.png">
        </div><div data-lg-item-id="11" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="11" src="./Theme Documentation - Basics - My New Hugo Site_files/scatter-dof.png">
        </div><div data-lg-item-id="12" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="12" src="./Theme Documentation - Basics - My New Hugo Site_files/scatter-and-gather-op.png">
        </div><div data-lg-item-id="13" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="13" src="./Theme Documentation - Basics - My New Hugo Site_files/dof-problem-1.png">
        </div><div data-lg-item-id="14" class="lg-thumb-item " style="width:80px; height: 60px;
            margin-right: 5px;">
            <img data-lg-item-id="14" src="./Theme Documentation - Basics - My New Hugo Site_files/scatter-as-gather-process.png">
        </div></div>
        </div></div>
            </div>
        </div>
        <scribe-shadow id="crxjs-ext" style="position: fixed; width: 0px; height: 0px; top: 0px; left: 0px; z-index: 2147483647; overflow: visible; visibility: visible;"><template shadowrootmode="open"><div id="root-scribe-elem" style="position: fixed; width: 0px; height: 0px; top: 0px; left: 0px; overflow: visible; color: rgb(15, 23, 42);"><div role="region" aria-label="Notifications (F8)" tabindex="-1" style="pointer-events: none;"><ol tabindex="-1" class="fixed bottom-auto right-0 top-0 z-[999999] flex max-h-screen w-[400px] max-w-full p-4"></ol></div></div><link rel="stylesheet" href="chrome-extension://okfkdaglfjjjfefdcppliegebpoegaii/assets/style.css"></template></scribe-shadow><div id="webhighlights-notificationshldjnlbobkdkghfidgoecgmklcemanhm"></div></body></html></div><div class="post-footer" id="post-footer">
    <div class="post-info">
        <div class="post-info-line">
            <div class="post-info-mod">
                <span>Updated on 0001-01-01</span>
            </div></div>
        <div class="post-info-line">
            <div class="post-info-md"></div>
            <div class="post-info-share">
                <span><a href="javascript:void(0);" title="Share on Twitter" data-sharer="twitter" data-url="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/" data-title=""><i class="fab fa-twitter fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Facebook" data-sharer="facebook" data-url="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/"><i class="fab fa-facebook-square fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Hacker News" data-sharer="hackernews" data-url="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/" data-title=""><i class="fab fa-hacker-news fa-fw" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on Line" data-sharer="line" data-url="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/" data-title=""><i data-svg-src="/lib/simple-icons/icons/line.min.svg" aria-hidden="true"></i></a><a href="javascript:void(0);" title="Share on 微博" data-sharer="weibo" data-url="http://192.168.0.124:1313/posts/depth-of-field/images/theme-documentation---basics---my-new-hugo-site/" data-title=""><i class="fab fa-weibo fa-fw" aria-hidden="true"></i></a></span>
            </div>
        </div>
    </div>

    <div class="post-info-more">
        <section class="post-tags"></section>
        <section>
            <span><a href="javascript:void(0);" onclick="window.history.back();">Back</a></span>&nbsp;|&nbsp;<span><a href="/">Home</a></span>
        </section>
    </div>

    <div class="post-nav">
            <a href="/posts/depth-of-field/" class="next" rel="next" title="Theme Documentation - Basics">Theme Documentation - Basics<i class="fas fa-angle-right fa-fw" aria-hidden="true"></i></a></div>
</div>
</article></div>
            </main><footer class="footer">
        <div class="footer-container"><div class="footer-line">Powered by <a href="https://gohugo.io/" target="_blank" rel="noopener noreffer" title="Hugo 0.135.0">Hugo</a> | Theme - <a href="https://github.com/dillonzq/LoveIt" target="_blank" rel="noopener noreffer" title="LoveIt 0.3.0"><i class="far fa-kiss-wink-heart fa-fw" aria-hidden="true"></i> LoveIt</a>
                </div><div class="footer-line" itemscope itemtype="http://schema.org/CreativeWork"><i class="far fa-copyright fa-fw" aria-hidden="true"></i><span itemprop="copyrightYear">2022 - 2025</span><span class="author" itemprop="copyrightHolder">&nbsp;<a href="/" target="_blank">xxxx</a></span></div>
        </div>
    </footer></div>

        <div id="fixed-buttons"><a href="#" id="back-to-top" class="fixed-button" title="Back to Top">
                <i class="fas fa-arrow-up fa-fw" aria-hidden="true"></i>
            </a><a href="#" id="view-comments" class="fixed-button" title="View Comments">
                <i class="fas fa-comment fa-fw" aria-hidden="true"></i>
            </a>
        </div><script type="text/javascript" src="/lib/autocomplete/autocomplete.min.js"></script><script type="text/javascript" src="/lib/lunr/lunr.min.js"></script><script type="text/javascript" src="/lib/lazysizes/lazysizes.min.js"></script><script type="text/javascript" src="/lib/clipboard/clipboard.min.js"></script><script type="text/javascript" src="/lib/sharer/sharer.min.js"></script><script type="text/javascript">window.config={"code":{"copyTitle":"Copy to clipboard","maxShownLines":50},"comment":{},"search":{"highlightTag":"em","maxResultLength":10,"noResultsFound":"No results found","snippetLength":30}};</script><script type="text/javascript" src="/js/theme.min.js"></script></body>
</html>
